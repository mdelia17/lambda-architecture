version: '3'

networks:
  net-lambda:
    name: net-lambda
    driver: bridge
  net-kafka:
    external:
      name: net-kafka
  net-cassandra:
    external:
      name: net-cassandra

services:    
  spark-master:
    image: bde2020/spark-master:3.1.1-hadoop3.2
    container_name: spark-master
    restart: on-failure
    ports:
      - "7077:7077"
    environment:
      - INIT_DAEMON_STEP=setup_spark
    networks:
      - net-lambda
      - net-cassandra
      - net-kafka
    volumes:
      - './spark-cassandra-connector-assembly-3.0.1-5-g8bab1061.jar:/spark/jars/spark-cassandra-connector-assembly-3.0.1-5-g8bab1061.jar'

  spark-worker-1:
    image: bde2020/spark-worker:3.1.1-hadoop3.2
    container_name: spark-worker-1
    restart: on-failure
    depends_on:
      - spark-master
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
    networks:
      - net-lambda
      - net-cassandra
      - net-kafka

  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    restart: on-failure
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
      - CLUSTER_NAME=test
    ports:
      - 9870:9870
      - 8020:8020
    networks:
      - net-lambda

  datanode-1:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode-1
    restart: on-failure
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
    ports:
      - 50075:50075
      - 50010:50010
    networks:
      - net-lambda

  datanode-2:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode-2
    restart: on-failure
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
    ports:
      - 50076:50076
      - 50011:50011
    networks:
      - net-lambda

  kafka-connect-cons:
    image: confluentinc/cp-kafka-connect-base:6.0.1
    container_name: kafka-connect-cons
    restart: on-failure
    ports:
      - 9067:9067
    networks:
      - net-lambda
      - net-kafka
    environment:
      CONNECT_BOOTSTRAP_SERVERS: "broker:29092"
      CONNECT_REST_ADVERTISED_HOST_NAME: "kafka-connect-cons"
      CONNECT_REST_PORT: 9067
      CONNECT_GROUP_ID: kafka-connect-cons-group
      CONNECT_CONFIG_STORAGE_TOPIC: kafka-connect-cons-configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_OFFSET_STORAGE_TOPIC: kafka-connect-cons-offsets
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_STATUS_STORAGE_TOPIC: kafka-connect-cons-status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema-registry:8081'
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_LOG4J_ROOT_LOGLEVEL: "INFO"
      CONNECT_LOG4J_APPENDER_STDOUT_LAYOUT_CONVERSIONPATTERN: "[%d] %p %X{connector.context}%m (%c:%L)%n"
      CONNECT_LOG4J_LOGGERS: "org.apache.kafka.connect.runtime.rest=WARN,org.reflections=ERROR"
      CONNECT_PLUGIN_PATH: '/usr/share/java,/usr/share/confluent-hub-components/'
    command: 
      - bash 
      - -c 
      - |
        echo "Installing connector plugins"
        confluent-hub install --no-prompt confluentinc/kafka-connect-hdfs3:1.1.1
        #
        # -----------
        # Launch the Kafka Connect worker
        /etc/confluent/docker/run &
        #
        # Don't exit
        sleep infinity

  datanode-3:
    image: bde2020/hadoop-datanode:2.0.0-hadoop2.7.4-java8
    container_name: datanode-3
    restart: on-failure
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:8020
    networks:
      - net-lambda

  hive-server:
    container_name: hive-server
    image: bde2020/hive:2.3.2-postgresql-metastore
    env_file:
      - ./hadoop-hive.env
    environment:
      HIVE_CORE_CONF_javax_jdo_option_ConnectionURL: "jdbc:postgresql://hive-metastore/metastore"
      SERVICE_PRECONDITION: "hive-metastore:9083"
    ports:
      - "10000:10000"
    networks:
      - net-lambda

  hive-metastore:
    container_name: hive-metastore
    image: bde2020/hive:2.3.2-postgresql-metastore
    env_file:
      - ./hadoop-hive.env
    command: /opt/hive/bin/hive --service metastore
    environment:
      SERVICE_PRECONDITION: "namenode:8020 datanode-3:50075 hive-metastore-postgresql:5432"
    ports:
      - "9083:9083"
    networks:
      - net-lambda

  hive-metastore-postgresql:
    container_name: hive-metastore-postgresql
    image: bde2020/hive-metastore-postgresql:2.3.0
    networks:
      - net-lambda

  presto-coordinator:
    image: shawnzhu/prestodb:0.181
    container_name: presto-coordinator
    ports:
      - "8080:8080"
    networks:
      - net-lambda